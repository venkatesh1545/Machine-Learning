{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["_AsTMXC3LuNm","tIymywKbz4jl"],"authorship_tag":"ABX9TyPjhv+waTPA64qGLA8iyA7a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Stemming**\n","\n","Stemming is the process of reducing a word to its word stem that affixes and prefixes or to the roots of words known as lemma. Stemming is important in natural language understanding(NLU) and natural language processing(NLP)"],"metadata":{"id":"b_EOnBUNwmPc"}},{"cell_type":"markdown","source":["# **Porter Stemmer**"],"metadata":{"id":"tbXLk6NyLHmE"}},{"cell_type":"code","execution_count":5,"metadata":{"id":"zoOMQbcpwZia","executionInfo":{"status":"ok","timestamp":1740832525256,"user_tz":-330,"elapsed":7,"user":{"displayName":"venkatesh golthi","userId":"14224435033662974193"}}},"outputs":[],"source":["from nltk.stem import PorterStemmer"]},{"cell_type":"code","source":["stemming = PorterStemmer()"],"metadata":{"id":"-7s2IdG7xMxZ","executionInfo":{"status":"ok","timestamp":1740832526553,"user_tz":-330,"elapsed":42,"user":{"displayName":"venkatesh golthi","userId":"14224435033662974193"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["words = [\"eating\", \"eats\", \"eaten\", \"writing\", \"writes\", \"programming\", \"programs\", \"history\", \"finally\", \"finalized\"]\n","for word in words:\n","  print(word+\"----->\" + stemming.stem(word))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R5IwvFo0yQhs","executionInfo":{"status":"ok","timestamp":1740832527708,"user_tz":-330,"elapsed":7,"user":{"displayName":"venkatesh golthi","userId":"14224435033662974193"}},"outputId":"4d71a724-1f6c-44ef-ecc0-a097ee9b1c3b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["eating----->eat\n","eats----->eat\n","eaten----->eaten\n","writing----->write\n","writes----->write\n","programming----->program\n","programs----->program\n","history----->histori\n","finally----->final\n","finalized----->final\n"]}]},{"cell_type":"code","source":["stemming.stem('congratulations')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"Wt_VGQpsy1xh","executionInfo":{"status":"ok","timestamp":1740832535537,"user_tz":-330,"elapsed":28,"user":{"displayName":"venkatesh golthi","userId":"14224435033662974193"}},"outputId":"7d585cfa-53a2-409c-a961-9198a564503a"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'congratul'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["stemming.stem('sitting')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"TYxxwZQ9zN8J","executionInfo":{"status":"ok","timestamp":1740498601407,"user_tz":-330,"elapsed":19,"user":{"displayName":"venkatesh golthi","userId":"14224435033662974193"}},"outputId":"981ab154-9aa3-47de-ef2b-969fad49fe9c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'sit'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["# **Lancaster Stemming**\n","\n","- A more aggressive stemming algorithm than Porter Stemmer.\n","- Often results in very short word stems, which may not always be useful.\n","\n","Example:\n","```\n","running → run\n","happiness → happy\n","```\n","\n","\n"],"metadata":{"id":"_AsTMXC3LuNm"}},{"cell_type":"code","source":["### Lancaster Stemming algorithm\n","from nltk.stem import LancasterStemmer"],"metadata":{"id":"NTs7dK1GzQQN","executionInfo":{"status":"ok","timestamp":1740832539195,"user_tz":-330,"elapsed":3,"user":{"displayName":"venkatesh golthi","userId":"14224435033662974193"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["lancaster = LancasterStemmer()"],"metadata":{"id":"P1fGuyd5zkLM","executionInfo":{"status":"ok","timestamp":1740832540236,"user_tz":-330,"elapsed":8,"user":{"displayName":"venkatesh golthi","userId":"14224435033662974193"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["for word in words:\n","  print(word + \"---->\" + lancaster.stem(word))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VRKE52Feznrp","executionInfo":{"status":"ok","timestamp":1740832541252,"user_tz":-330,"elapsed":17,"user":{"displayName":"venkatesh golthi","userId":"14224435033662974193"}},"outputId":"25b9b4e0-d2df-4652-bf9c-efbcf40beae8"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["eating---->eat\n","eats---->eat\n","eaten---->eat\n","writing---->writ\n","writes---->writ\n","programming---->program\n","programs---->program\n","history---->hist\n","finally---->fin\n","finalized---->fin\n"]}]},{"cell_type":"markdown","source":["# **RegexpStemmer Class**\n","NLTK has RegexStemmer class with the help of which we can easily implement Regular Expression Stemmer Algorithms. It basically takes a single regular expression and removes any prefix or suffix that matches the expression. Let us see an example:"],"metadata":{"id":"tIymywKbz4jl"}},{"cell_type":"code","source":["from nltk.stem import RegexpStemmer"],"metadata":{"id":"BC125kERzpdV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reg_stemmer = RegexpStemmer('ing|s$|e$|able$', min = 4) ### or else you can use here ing$ for checking last characters of the string."],"metadata":{"id":"gh7My5ib0Zzf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reg_stemmer.stem(\"eating\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"O0h6m3-z4Ybt","executionInfo":{"status":"ok","timestamp":1740505121054,"user_tz":-330,"elapsed":22,"user":{"displayName":"venkatesh golthi","userId":"14224435033662974193"}},"outputId":"1f6144d6-d160-42e6-f196-ed854dba29dd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'eat'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["reg_stemmer.stem(\"ingplaying\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"1ZYeN8O64sDn","executionInfo":{"status":"ok","timestamp":1740505122334,"user_tz":-330,"elapsed":18,"user":{"displayName":"venkatesh golthi","userId":"14224435033662974193"}},"outputId":"923e9140-0e65-4f62-ff82-edb37a5c675a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'play'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":[],"metadata":{"id":"ghTxdC2H4yD4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Snowball Stemmer**\n","- An improved version of Porter Stemmer.\n","- More efficient and provides better accuracy.\n","- Supports multiple languages.\n","\n","Example:\n","```\n","running → run\n","happiness → happi\n","\n","```\n","\n","\n"],"metadata":{"id":"SE6gL0_l5Y69"}},{"cell_type":"code","source":["from nltk.stem import SnowballStemmer"],"metadata":{"id":"kOacMrdy5Yc0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["SnowballStemmer = SnowballStemmer('english', ignore_stopwords = False)"],"metadata":{"id":"peaPk6bY53sC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for word in words:\n","  print(word + \"--->\" + SnowballStemmer.stem(word))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C1iq3hMj6AJz","executionInfo":{"status":"ok","timestamp":1740500400974,"user_tz":-330,"elapsed":67,"user":{"displayName":"venkatesh golthi","userId":"14224435033662974193"}},"outputId":"85e6a015-21fc-4a6a-90a7-8722c0fada0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["eating--->eat\n","eats--->eat\n","eaten--->eaten\n","writing--->write\n","writes--->write\n","programming--->program\n","programs--->program\n","history--->histori\n","finally--->final\n","finalized--->final\n"]}]},{"cell_type":"code","source":["stemming.stem(\"fairly\"), stemming.stem(\"sportingly\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iCrSYUP-6Hli","executionInfo":{"status":"ok","timestamp":1740500436499,"user_tz":-330,"elapsed":28,"user":{"displayName":"venkatesh golthi","userId":"14224435033662974193"}},"outputId":"4ea0f9c5-8f3a-4819-c6ca-6287a8876ca2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('fairli', 'sportingli')"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["SnowballStemmer.stem(\"fairly\"), SnowballStemmer.stem(\"sportingly\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5FOz1L_O6QRO","executionInfo":{"status":"ok","timestamp":1740500453382,"user_tz":-330,"elapsed":47,"user":{"displayName":"venkatesh golthi","userId":"14224435033662974193"}},"outputId":"9675781f-03f4-45b9-bb19-daa2db60b09d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('fair', 'sport')"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","source":["# **Wordnet Lemmatizer**\n","Lemmatization technique is like stemming. The output we will get after lemmatization is called 'lemma', which is a root word rather than root stem, the output of stemming. After lemmatization, we will be getting a valid word that means the same thing.\n","\n","NLTK provides WordNetLemmatizer class which is a thin wrapper around the wordnet corpus. This class uses `morphy()` function to the WordNet CorpusReader class to find a lemma. Let us understand it with an example."],"metadata":{"id":"8Ig2xeNU6cLK"}},{"cell_type":"code","source":["import nltk\n","nltk.download('wordnet')\n","\n","from nltk.stem import WordNetLemmatizer\n","\n","lemmatizer = WordNetLemmatizer()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JufN4Kup6az9","executionInfo":{"status":"ok","timestamp":1740500848202,"user_tz":-330,"elapsed":319,"user":{"displayName":"venkatesh golthi","userId":"14224435033662974193"}},"outputId":"7bc38a38-9c6b-45b1-aa83-8d57adedb94d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]}]},{"cell_type":"code","source":["for word in words:\n","  print(word + \"--->\" + lemmatizer.lemmatize(word))\n","\n","# '''\n","# default notation of lemmatization\n","\n","# def lemmatize(self, word: str, pos: str = \"n\")\n","\n","# POS - Noun - n\n","# verb - v\n","# adjective - a\n","# adverb - r\n","# '''\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":226},"id":"jx54IEBJ6aiw","executionInfo":{"status":"ok","timestamp":1740501156917,"user_tz":-330,"elapsed":32,"user":{"displayName":"venkatesh golthi","userId":"14224435033662974193"}},"outputId":"b0c241da-5edf-472d-90fd-94328fbb7d70"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["eating--->eating\n","eats--->eats\n","eaten--->eaten\n","writing--->writing\n","writes--->writes\n","programming--->programming\n","programs--->program\n","history--->history\n","finally--->finally\n","finalized--->finalized\n"]},{"output_type":"execute_result","data":{"text/plain":["'\\ndef lemmatize(self, word: str, pos: str = \"n\")\\n\\nPOS - Noun - n\\nverb - v\\nadjective - a\\nadverb - r\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["for word in words:\n","  print(word + \"--->\" + lemmatizer.lemmatize(word, pos='v'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dJGY9vMR6UYw","executionInfo":{"status":"ok","timestamp":1740501254230,"user_tz":-330,"elapsed":19,"user":{"displayName":"venkatesh golthi","userId":"14224435033662974193"}},"outputId":"2a29810a-b3f3-474a-9fae-72a2f46faa85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["eating--->eat\n","eats--->eat\n","eaten--->eat\n","writing--->write\n","writes--->write\n","programming--->program\n","programs--->program\n","history--->history\n","finally--->finally\n","finalized--->finalize\n"]}]},{"cell_type":"code","source":["for word in words:\n","  print(word + \"--->\" + lemmatizer.lemmatize(word, pos='a'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IokkSYJH9Vw0","executionInfo":{"status":"ok","timestamp":1740501289492,"user_tz":-330,"elapsed":19,"user":{"displayName":"venkatesh golthi","userId":"14224435033662974193"}},"outputId":"e9075c7b-6625-4907-f40c-fce34f34afac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["eating--->eating\n","eats--->eats\n","eaten--->eaten\n","writing--->writing\n","writes--->writes\n","programming--->programming\n","programs--->programs\n","history--->history\n","finally--->finally\n","finalized--->finalized\n"]}]},{"cell_type":"code","source":["lemmatizer.lemmatize(\"good\", pos='v')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"HBTgtntx9ghe","executionInfo":{"status":"ok","timestamp":1740501329726,"user_tz":-330,"elapsed":31,"user":{"displayName":"venkatesh golthi","userId":"14224435033662974193"}},"outputId":"bbf081f7-54e3-40f5-ecda-9d05fcbfc0eb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'good'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["### sentiment analysis -- stemming\n","### chatbot ---> Lemmatization"],"metadata":{"id":"1m6lkMEL9oBg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zrjuJ79C956c"},"execution_count":null,"outputs":[]}]}